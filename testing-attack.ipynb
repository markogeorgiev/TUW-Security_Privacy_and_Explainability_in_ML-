{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T00:13:48.825905Z",
     "start_time": "2025-04-09T00:13:47.697017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "def get_prepared_data(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df[\"default\"] = df[\"default\"].map({1: 0, 2: 1})  # 0 = good, 1 = bad\n",
    "    \n",
    "    df['savings_unknown'] = df['savings'].str.lower().eq('unknown').astype(int)\n",
    "    df['checking_account_none'] = df['checking_account'].str.lower().str.contains('no checking').astype(int)\n",
    "    \n",
    "    df['savings_numeric'] = pd.to_numeric(df['savings'], errors='coerce')\n",
    "    df['checking_account_numeric'] = pd.to_numeric(df['checking_account'], errors='coerce')\n",
    "    \n",
    "    df['savings_numeric'] = df.groupby('default')['savings_numeric'].transform(lambda x: x.fillna(x.median()))\n",
    "    df['checking_account_numeric'] = df.groupby('default')['checking_account_numeric'].transform(lambda x: x.fillna(x.median()))\n",
    "    \n",
    "    \n",
    "    df.drop(columns=['savings', 'checking_account'], inplace=True)\n",
    "    \n",
    "    def bucket_employment_since(val):\n",
    "        val = str(val).strip().lower()\n",
    "        if val == 'unemployed':\n",
    "            return 'unemployed'\n",
    "        if val == '<1 year' or val in ['1', '2', '3', '4']:\n",
    "            return 'short'\n",
    "        elif val in ['5', '6', '7']:\n",
    "            return 'medium'\n",
    "        else:\n",
    "            return 'long'\n",
    "    \n",
    "    df['employment_since_bucket'] = df['employment_since'].apply(bucket_employment_since)\n",
    "    df.drop(columns=['employment_since'], inplace=True)\n",
    "    \n",
    "    def bucket_monthly_rent(val):\n",
    "        if val == 0:\n",
    "            return 'none'\n",
    "        elif val <= 200:\n",
    "            return 'low'\n",
    "        elif val <= 400:\n",
    "            return 'medium'\n",
    "        else:\n",
    "            return 'high'\n",
    "    \n",
    "    def bucket_credit_amount(val):\n",
    "        if val <= 1000:\n",
    "            return 'very_low'\n",
    "        elif val <= 3000:\n",
    "            return 'low'\n",
    "        elif val <= 6000:\n",
    "            return 'medium'\n",
    "        else:\n",
    "            return 'high'\n",
    "    \n",
    "    def bucket_duration(val):\n",
    "        if val <= 12:\n",
    "            return 'short'\n",
    "        elif val <= 24:\n",
    "            return 'medium'\n",
    "        elif val <= 48:\n",
    "            return 'long'\n",
    "        else:\n",
    "            return 'very_long'\n",
    "    \n",
    "    def bucket_age(val):\n",
    "        if val <= 25:\n",
    "            return 'young'\n",
    "        elif val <= 40:\n",
    "            return 'adult'\n",
    "        elif val <= 60:\n",
    "            return 'mature'\n",
    "        else:\n",
    "            return 'senior'\n",
    "    \n",
    "    df['monthly_rent_bucket'] = df['monthly_rent_or_mortgage'].apply(bucket_monthly_rent)\n",
    "    df['credit_amount_bucket'] = df['credit_amount'].apply(bucket_credit_amount)\n",
    "    df['duration_bucket'] = df['duration'].apply(bucket_duration)\n",
    "    df['age_bucket'] = df['age'].apply(bucket_age)\n",
    "    \n",
    "    df.drop(columns=['monthly_rent_or_mortgage', 'credit_amount', 'duration', 'age'], inplace=True)\n",
    "    \n",
    "    # Drop PID\n",
    "    df.drop(\"PID\", axis=1, inplace=True)\n",
    "    \n",
    "    # === Encode remaining categorical columns ===\n",
    "    categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "    \n",
    "    encoder = OrdinalEncoder(dtype=int)\n",
    "    df[categorical_cols] = encoder.fit_transform(df[categorical_cols]) + 1\n",
    "\n",
    "    return df"
   ],
   "id": "2b590be93c0d33bb",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T00:13:49.546676Z",
     "start_time": "2025-04-09T00:13:49.523114Z"
    }
   },
   "cell_type": "code",
   "source": "df_original = get_prepared_data('Financial_Records.csv')",
   "id": "fee35d433936e423",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T00:13:38.194163Z",
     "start_time": "2025-04-09T00:13:38.163674Z"
    }
   },
   "cell_type": "code",
   "source": "df_modified = get_prepared_data('Cleaned_Financial_Records.csv')",
   "id": "2b759810bfaeb3c0",
   "outputs": [],
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-09T00:13:55.781559Z",
     "start_time": "2025-04-09T00:13:55.775457Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_noise_to_numeric(df, numeric_cols, noise_level=0.05, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    noisy_df = df.copy()\n",
    "    for col in numeric_cols:\n",
    "        if col in noisy_df:\n",
    "            std_dev = noisy_df[col].std()\n",
    "            noise = np.random.normal(0, noise_level * std_dev, size=len(noisy_df))\n",
    "            noisy_df[col] += noise\n",
    "            # Optional: clamp to original min/max\n",
    "            noisy_df[col] = noisy_df[col].clip(lower=df[col].min(), upper=df[col].max())\n",
    "    return noisy_df\n",
    "\n",
    "def add_noise_to_categorical(df, cat_cols, flip_prob=0.05, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    noisy_df = df.copy()\n",
    "    for col in cat_cols:\n",
    "        if col in noisy_df:\n",
    "            unique_vals = df[col].unique()\n",
    "            mask = np.random.rand(len(df)) < flip_prob\n",
    "            random_vals = np.random.choice(unique_vals, size=mask.sum())\n",
    "            noisy_df.loc[mask, col] = random_vals\n",
    "    return noisy_df\n",
    "\n",
    "numeric_cols = ['age', 'credit_amount', 'duration', 'installment_rate',\n",
    "                'existing_credits', 'liable_people', 'residence_since', 'monthly_rent_or_mortgage']\n",
    "\n",
    "categorical_cols = ['sex', 'marital_status', 'job', 'employment_since', 'foreign',\n",
    "                    'credit_history', 'purpose', 'debtors', 'checking_account',\n",
    "                    'savings', 'housing', 'property']\n",
    "\n",
    "df_noisy = add_noise_to_numeric(df, numeric_cols, noise_level=0.10)\n",
    "df_noisy = add_noise_to_categorical(df_noisy, categorical_cols, flip_prob=0.10)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import entropy\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import numpy as np\n",
    "\n",
    "# === Distribution plots (better formatting) ===\n",
    "columns_to_plot = ['credit_amount_bucket', 'savings_numeric', 'duration_bucket', 'age_bucket']\n",
    "\n",
    "for col in columns_to_plot:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    \n",
    "    if df_original[col].dtype == 'object' or 'bucket' in col.lower():\n",
    "        orig_counts = df_original[col].value_counts(normalize=True).sort_index()\n",
    "        mod_counts = df_modified[col].value_counts(normalize=True).reindex(orig_counts.index).fillna(0)\n",
    "\n",
    "        x = np.arange(len(orig_counts))\n",
    "        width = 0.35\n",
    "        plt.bar(x - width/2, orig_counts.values, width, label='Original', color='blue', alpha=0.7)\n",
    "        plt.bar(x + width/2, mod_counts.values, width, label='Modified', color='orange', alpha=0.7)\n",
    "        plt.xticks(ticks=x, labels=orig_counts.index, rotation=45)\n",
    "        plt.ylabel('Proportion')\n",
    "        plt.title(f'Distribution of {col}')\n",
    "    else:\n",
    "        sns.kdeplot(df_original[col], label='Original', fill=True, linewidth=1.5)\n",
    "        sns.kdeplot(df_modified[col], label='Modified', fill=True, linewidth=1.5)\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Density')\n",
    "        plt.title(f'Distribution of {col}')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n== Mean & Standard Deviation Differences ==\")\n",
    "numeric_cols = df_original.select_dtypes(include='number').columns.drop(\"default\")\n",
    "\n",
    "for col in numeric_cols:\n",
    "    mean_diff = abs(df_original[col].mean() - df_modified[col].mean())\n",
    "    std_diff = abs(df_original[col].std() - df_modified[col].std())\n",
    "    print(f\"{col:<30}: mean diff = {mean_diff:.4f}, std diff = {std_diff:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\n== Largest Correlation Changes ==\")\n",
    "orig_corr = df_original[numeric_cols].corr()\n",
    "mod_corr = df_modified[numeric_cols].corr()\n",
    "corr_diff = (orig_corr - mod_corr).abs()\n",
    "\n",
    "corr_diff_unstacked = corr_diff.where(np.triu(np.ones(corr_diff.shape), k=1).astype(bool))\n",
    "largest_diffs = corr_diff_unstacked.stack().sort_values(ascending=False).head(10)\n",
    "print(largest_diffs)\n",
    "\n",
    "def kl_divergence(col):\n",
    "    p = df_original[col].value_counts(normalize=True).sort_index()\n",
    "    q = df_modified[col].value_counts(normalize=True).reindex(p.index).fillna(0)\n",
    "    return entropy(p, q)\n",
    "\n",
    "bucketed_features = ['age_bucket', 'checking_account_numeric', 'savings_numeric', 'duration_bucket']\n",
    "\n",
    "print(\"\\n== Average Pairwise Distance ==\")\n",
    "sample_cols = numeric_cols[:10]\n",
    "\n",
    "orig_sample = df_original[sample_cols].sample(500, random_state=42)\n",
    "mod_sample = df_modified[sample_cols].sample(500, random_state=42)\n",
    "\n",
    "orig_dist = pairwise_distances(orig_sample, metric='euclidean')\n",
    "mod_dist = pairwise_distances(mod_sample, metric='euclidean')\n",
    "\n",
    "print(f\"Original avg pairwise distance: {orig_dist.mean():.4f}\")\n",
    "print(f\"Modified avg pairwise distance: {mod_dist.mean():.4f}\")"
   ],
   "outputs": [],
   "execution_count": 69
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

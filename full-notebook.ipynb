{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Full attack & Comparison",
   "id": "20e5d0a65fcebc91"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!python.exe .\\dataset-shuffler.py Financial_Records.csv Shuffled_Financial_Records.csv \"Marko123!@#\"",
   "id": "1a7e22f3342be8eb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Attack Code ",
   "id": "e9bb1b23e634f75"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import random\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Shuffled_Financial_Records.csv\")\n",
    "\n",
    "# Set seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "### STEP 1: UID MANIPULATION ###\n",
    "# Generate a synthetic UID from stable features and assign back to PID\n",
    "def generate_uid(row, cols):\n",
    "    concat_str = ''.join(str(row[col]) for col in cols)\n",
    "    return int(hashlib.sha256(concat_str.encode()).hexdigest(), 16) % 10**8\n",
    "\n",
    "uid_cols = ['age', 'sex', 'job', 'residence_since', 'property', 'housing']\n",
    "df['PID'] = df.apply(lambda row: generate_uid(row, uid_cols), axis=1)\n",
    "\n",
    "### STEP 2: BIT COLLISION ENGINEERING ###\n",
    "\n",
    "# Categorical columns to attack\n",
    "categorical_cols = [\n",
    "    'sex', 'marital_status', 'job', 'credit_hist', 'purpose', 'debtors',\n",
    "    'property', 'installment_other', 'housing', 'tel', 'online_banking', 'foreign'\n",
    "]\n",
    "\n",
    "# Function to randomly flip categorical values\n",
    "def perturb_categorical(col):\n",
    "    top_values = df[col].value_counts().nlargest(5).index.tolist()\n",
    "    df[col] = df[col].apply(lambda x: random.choice(top_values) if random.random() < 0.3 else x)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    perturb_categorical(col)\n",
    "\n",
    "# Mixed-type columns: numeric part perturbation only\n",
    "def perturb_mixed_numeric(col, value_range=0.1):\n",
    "    numeric_mask = pd.to_numeric(df[col], errors='coerce').notnull()\n",
    "    numeric_values = df.loc[numeric_mask, col].astype(float)\n",
    "    noise = np.random.uniform(-value_range, value_range, size=numeric_values.shape[0])\n",
    "    perturbed = (numeric_values * (1 + noise)).clip(lower=0).round().astype(int)\n",
    "    df.loc[numeric_mask, col] = perturbed\n",
    "\n",
    "perturb_mixed_numeric('employment_since', 0.2)\n",
    "perturb_mixed_numeric('checking_account', 0.25)\n",
    "perturb_mixed_numeric('savings', 0.25)\n",
    "\n",
    "# Numeric columns to attack\n",
    "numeric_cols = [\n",
    "    'age', 'credit_amount', 'duration', 'installment_rate',\n",
    "    'residence_since', 'existing_credits', 'liable_people',\n",
    "    'monthly_rent_or_mortgage'\n",
    "]\n",
    "\n",
    "def perturb_numeric(col, shift_percent=0.1):\n",
    "    values = df[col].astype(float)\n",
    "    noise = np.random.normal(loc=0, scale=shift_percent, size=len(values))\n",
    "    df[col] = (values * (1 + noise)).clip(lower=0).round().astype(int)\n",
    "\n",
    "for col in numeric_cols:\n",
    "    perturb_numeric(col, 0.15)\n",
    "\n",
    "# Binary numeric columns (1 or 2) â€” flip occasionally\n",
    "def flip_binary(col, prob=0.15):\n",
    "    df[col] = df[col].apply(lambda x: 3 - x if random.random() < prob else x)\n",
    "\n",
    "flip_binary('default', prob=0.2)\n",
    "\n",
    "# Ensure all numeric columns are integers\n",
    "for col in df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df[col]):\n",
    "        df[col] = df[col].round().astype(int)\n",
    "\n",
    "# Save the attacked dataset\n",
    "df.to_csv(\"Attacked_Financial_Records.csv\", index=False)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparation of The Data for Comparison",
   "id": "7a045d37250c9a38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "def prepare_dataset_for_fidelity(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepares the dataset for fidelity comparison by:\n",
    "    - Converting numeric columns to float (dropping invalids)\n",
    "    - Standardizing categorical values\n",
    "    - Encoding employment_since according to custom mapping (unemployed -> -1, 1<year -> 0)\n",
    "    \"\"\"\n",
    "\n",
    "    numeric_columns = [\n",
    "        \"age\", \"credit_amount\", \"duration\", \"monthly_rent_or_mortgage\",\n",
    "        \"installment_rate\", \"residence_since\", \"existing_credits\",\n",
    "        \"liable_people\", \"default\"  \n",
    "    ]\n",
    "    \n",
    "    categorical_columns = [\n",
    "        \"sex\", \"marital_status\", \"job\", \"credit_hist\", \"purpose\", \"debtors\",\n",
    "        \"property\", \"installment_other\", \"housing\", \"tel\", \"online_banking\",\n",
    "        \"foreign\"\n",
    "    ]\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1. Clean and convert numeric columns\n",
    "    for col in numeric_columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')  # force conversion to numeric\n",
    "        # Drop rows with NaN in numeric columns (or impute if preferred)\n",
    "        df = df[df[col].notna()]\n",
    "\n",
    "    # 2. Clean categorical columns (standardize text)\n",
    "    for col in categorical_columns:\n",
    "        df[col] = df[col].astype(str).str.strip().str.lower()\n",
    "\n",
    "    # 3. Custom handling for employment_since\n",
    "    def convert_employment(val):\n",
    "        val = str(val).strip().lower()\n",
    "        if val == 'unemployed':\n",
    "            return -1\n",
    "        elif val == '<1 year':\n",
    "            return 0\n",
    "        else:\n",
    "            try:\n",
    "                return float(val)\n",
    "            except ValueError:\n",
    "                return None\n",
    "\n",
    "    df[\"employment_since\"] = df[\"employment_since\"].apply(convert_employment)\n",
    "    df = df[df[\"employment_since\"].notna()]\n",
    "    \n",
    "    # 4. Handling mixed-type 'checking_account'\n",
    "    def clean_checking_account(val):\n",
    "        val = str(val).strip().lower()\n",
    "        if val == 'no checking account':\n",
    "            return val  # keep as string\n",
    "        try:\n",
    "            return float(val)  # keep numeric\n",
    "        except ValueError:\n",
    "            return None  # invalid entries removed\n",
    "\n",
    "    df[\"checking_account\"] = df[\"checking_account\"].apply(clean_checking_account)\n",
    "    df = df[df[\"checking_account\"].notna()]\n",
    "\n",
    "    return df"
   ],
   "id": "40b020a92d4e7478"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Comparison Code",
   "id": "93263575e5eda0d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import numpy as np\n",
    "\n",
    "def compare_fidelity(prepared_df: pd.DataFrame, prepared_df_modified: pd.DataFrame):\n",
    "    results = []\n",
    "\n",
    "    # Define columns by type\n",
    "    numeric_columns = [\n",
    "        \"age\", \"credit_amount\", \"duration\", \"monthly_rent_or_mortgage\",\n",
    "        \"installment_rate\", \"residence_since\", \"existing_credits\",\n",
    "        \"liable_people\", \"default\", \"employment_since\"\n",
    "    ]\n",
    "    \n",
    "    categorical_columns = [\n",
    "        \"sex\", \"marital_status\", \"job\", \"credit_hist\", \"purpose\", \"debtors\",\n",
    "        \"property\", \"installment_other\", \"housing\", \"tel\", \"online_banking\",\n",
    "        \"foreign\"\n",
    "    ]\n",
    "\n",
    "    # 1. Purely Numeric Columns\n",
    "    for col in numeric_columns:\n",
    "        # Ensure both columns are numeric and drop rows with NaNs\n",
    "        original_values = prepared_df[col]\n",
    "        modified_values = prepared_df_modified[col]\n",
    "        valid_mask = original_values.notna() & modified_values.notna()\n",
    "\n",
    "        mse = mean_squared_error(original_values[valid_mask], modified_values[valid_mask])\n",
    "        results.append({\n",
    "            \"column\": col,\n",
    "            \"type\": \"numeric\",\n",
    "            \"MSE\": mse\n",
    "        })\n",
    "\n",
    "    # 2. Purely Categorical Columns\n",
    "    for col in categorical_columns:\n",
    "        original_values = prepared_df[col].astype(str)\n",
    "        modified_values = prepared_df_modified[col].astype(str)\n",
    "\n",
    "        # Agreement Rate\n",
    "        match_mask = original_values == modified_values\n",
    "        agreement_rate = match_mask.sum() / len(match_mask)\n",
    "\n",
    "        # JSD on distributions\n",
    "        dist_orig = original_values.value_counts(normalize=True).sort_index()\n",
    "        dist_mod = modified_values.value_counts(normalize=True).sort_index()\n",
    "\n",
    "        # Align index\n",
    "        all_categories = sorted(set(dist_orig.index).union(dist_mod.index))\n",
    "        p = np.array([dist_orig.get(cat, 0) for cat in all_categories])\n",
    "        q = np.array([dist_mod.get(cat, 0) for cat in all_categories])\n",
    "        jsd = jensenshannon(p, q)\n",
    "\n",
    "        results.append({\n",
    "            \"column\": col,\n",
    "            \"type\": \"categorical\",\n",
    "            \"Agreement Rate\": agreement_rate,\n",
    "            \"JSD\": jsd\n",
    "        })\n",
    "\n",
    "    # 3. Mixed-Type: checking_account\n",
    "    checking_orig = prepared_df[\"checking_account\"]\n",
    "    checking_mod = prepared_df_modified[\"checking_account\"]\n",
    "\n",
    "    # Numeric part\n",
    "    numeric_mask = checking_orig.apply(lambda x: isinstance(x, float)) & \\\n",
    "                   checking_mod.apply(lambda x: isinstance(x, float))\n",
    "    if numeric_mask.sum() > 0:\n",
    "        mse_checking = mean_squared_error(checking_orig[numeric_mask], checking_mod[numeric_mask])\n",
    "    else:\n",
    "        mse_checking = None\n",
    "\n",
    "    # Categorical part ('no checking account')\n",
    "    cat_mask = checking_orig == \"no checking account\"\n",
    "    mod_cat_mask = checking_mod == \"no checking account\"\n",
    "    agreement_mask = cat_mask & mod_cat_mask\n",
    "    agreement_count = agreement_mask.sum()\n",
    "    total_cat = (cat_mask | mod_cat_mask).sum()\n",
    "    cat_agreement_rate = agreement_count / total_cat if total_cat > 0 else None\n",
    "\n",
    "    # Distributional comparison for 'no checking account' frequency\n",
    "    dist_orig_check = checking_orig[checking_orig == \"no checking account\"]\n",
    "    dist_mod_check = checking_mod[checking_mod == \"no checking account\"]\n",
    "    p_check = np.array([len(dist_orig_check) / len(checking_orig)])\n",
    "    q_check = np.array([len(dist_mod_check) / len(checking_mod)])\n",
    "    jsd_checking = jensenshannon(p_check, q_check)\n",
    "\n",
    "    results.append({\n",
    "        \"column\": \"checking_account\",\n",
    "        \"type\": \"mixed\",\n",
    "        \"MSE (numeric)\": mse_checking,\n",
    "        \"Agreement Rate (categorical)\": cat_agreement_rate,\n",
    "        \"JSD (categorical)\": jsd_checking\n",
    "    })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ],
   "id": "e5991bc2a8557f59"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualizing the Comparison",
   "id": "b36a3a5e4f41ac2b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.read_csv('Shuffled_Financial_Records.csv')\n",
    "df_modified = pd.read_csv('Attacked_Financial_Records.csv')\n",
    "\n",
    "prepared_df = prepare_dataset_for_fidelity(df)\n",
    "prepared_df_modified = prepare_dataset_for_fidelity(df_modified)\n",
    "\n",
    "results_df = compare_fidelity(prepared_df, prepared_df_modified)"
   ],
   "id": "e9fec64ecc6ddb1d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "results_df.head(22)",
   "id": "32091fff9483dbec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## V1: First version of the attack \n",
    "This version doesn't work as I don't handle mixed values right. E.g. columns like employment_since, stay same across cleaned and original datasets"
   ],
   "id": "a04bc3158e3f4471"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T01:42:18.662878Z",
     "start_time": "2025-04-23T01:40:39.961135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from dataset_uniqueness_utils import *\n",
    "\n",
    "DATA_DIR = \"datasets-p2\"\n",
    "OUT_DIR = \"output-datasets\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "unique_datasets, unique_names, num_unique = get_unique_datasets(DATA_DIR) \n",
    "\n",
    "print(f\"Using {num_unique} unique datasets:\")\n",
    "for name in unique_names:\n",
    "    print(f\" - {name}\")\n",
    "\n",
    "base_df = unique_datasets[0].copy()\n",
    "modification_log = []\n",
    "\n",
    "for row in range(base_df.shape[0]):\n",
    "    for col in base_df.columns:\n",
    "        values = [df.at[row, col] for df in unique_datasets]\n",
    "        try:\n",
    "            float_values = [float(v) for v in values]\n",
    "            is_numeric = True\n",
    "        except:\n",
    "            is_numeric = False\n",
    "\n",
    "        if is_numeric:\n",
    "            std_dev = np.std(float_values)\n",
    "            if std_dev < 1e-4:\n",
    "                cleaned_value = round(np.mean(float_values), 4)\n",
    "            else:\n",
    "                rounded = [round(v, 4) for v in float_values]\n",
    "                most_common = Counter(rounded).most_common(1)[0][0]\n",
    "                cleaned_value = most_common\n",
    "        else:\n",
    "            most_common = Counter(values).most_common(1)[0][0]\n",
    "            cleaned_value = most_common\n",
    "\n",
    "        if any(val != cleaned_value for val in values):\n",
    "            modification_log.append({\n",
    "                \"row\": row,\n",
    "                \"column\": col,\n",
    "                \"original_values\": values,\n",
    "                \"cleaned_value\": cleaned_value\n",
    "            })\n",
    "\n",
    "        base_df.at[row, col] = cleaned_value\n",
    "        \n",
    "save_cleaned_output_versioned(base_df, modification_log, num_unique)"
   ],
   "id": "f8e07a104bf99dd2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 unique datasets:\n",
      " - Financial_Records.csv\n",
      " - Financial_Records_Bob.csv\n",
      " - Financial_Records_Bob_Nemanja_Saveski.csv\n",
      " - Financial_Records_Bob_Thomas_Senstyler.csv\n",
      "Cleaned dataset saved as 'Financial_Records_No_Fingerprint_4_v4.csv' in 'output-datasets\\4_v4'\n",
      "Modification log saved as 'modification_log_4_v4.csv' in 'output-datasets\\4_v4'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output-datasets\\\\4_v4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## V2: Currently best version\n",
    "This version addresses the issue from V1. Also stores data as integers (like in the original), and not float like V1"
   ],
   "id": "d4dbe90da5593ded"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:09:42.127421Z",
     "start_time": "2025-04-23T08:08:12.296799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "from dataset_uniqueness_utils import *\n",
    "\n",
    "def is_floatable(x):\n",
    "    try:\n",
    "        float(x)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "DATA_DIR = \"datasets-p2\"\n",
    "OUT_DIR = \"output-datasets\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "unique_datasets, unique_names, num_unique = get_unique_datasets(DATA_DIR)\n",
    "\n",
    "print(f\"Using {num_unique} unique datasets:\")\n",
    "for name in unique_names:\n",
    "    print(f\" - {name}\")\n",
    "\n",
    "base_df = unique_datasets[0].copy()\n",
    "modification_log = []\n",
    "\n",
    "for row in range(base_df.shape[0]):\n",
    "    for col in base_df.columns:\n",
    "        values = [df.at[row, col] for df in unique_datasets]\n",
    "\n",
    "        float_values = []\n",
    "        num_parseable = 0\n",
    "        for v in values:\n",
    "            try:\n",
    "                float_values.append(float(v))\n",
    "                num_parseable += 1\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        if num_parseable == len(values):\n",
    "            std_dev = np.std(float_values)\n",
    "            if std_dev < 1e-4:\n",
    "                cleaned_value = round(np.mean(float_values), 4)\n",
    "            else:\n",
    "                rounded = [round(v, 4) for v in float_values]\n",
    "                most_common = Counter(rounded).most_common(1)[0][0]\n",
    "                cleaned_value = most_common\n",
    "\n",
    "        elif num_parseable == 0:\n",
    "            most_common = Counter(values).most_common(1)[0][0]\n",
    "            cleaned_value = most_common\n",
    "\n",
    "        else:\n",
    "            if random.random() < 0.5:\n",
    "                cleaned_value = round(np.mean(float_values), 4)\n",
    "            else:\n",
    "                cleaned_value = random.choice([v for v in values if not is_floatable(v)])\n",
    "\n",
    "        if any(val != cleaned_value for val in values):\n",
    "            modification_log.append({\n",
    "                \"row\": row,\n",
    "                \"column\": col,\n",
    "                \"original_values\": values,\n",
    "                \"cleaned_value\": cleaned_value\n",
    "            })\n",
    "\n",
    "        try:\n",
    "            base_df.at[row, col] = int(float(cleaned_value))\n",
    "        except:\n",
    "            base_df.at[row, col] = cleaned_value\n",
    "\n",
    "save_cleaned_output_versioned(base_df, modification_log, num_unique)\n"
   ],
   "id": "38316076467459c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 unique datasets:\n",
      " - Financial_Records.csv\n",
      " - Financial_Records_Bob.csv\n",
      " - Financial_Records_Bob_Nemanja_Saveski.csv\n",
      " - Financial_Records_Bob_Thomas_Senstyler.csv\n",
      "Cleaned dataset saved as 'Financial_Records_No_Fingerprint_4_v5.csv' in 'output-datasets\\4_v5'\n",
      "Modification log saved as 'modification_log_4_v5.csv' in 'output-datasets\\4_v5'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output-datasets\\\\4_v5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "97569137cc02afa3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## V1: First version of the attack \n",
    "This version doesn't work as I don't handle mixed values right. E.g. columns like employment_since, stay same across cleaned and original datasets"
   ],
   "id": "a04bc3158e3f4471"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T11:28:47.469794Z",
     "start_time": "2025-04-23T11:28:44.042227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from dataset_uniqueness_utils import *\n",
    "\n",
    "DATA_DIR = \"datasets-p2\"\n",
    "OUT_DIR = \"output-datasets\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "unique_datasets, unique_names, num_unique = get_unique_datasets(DATA_DIR) \n",
    "\n",
    "print(f\"Using {num_unique} unique datasets:\")\n",
    "for name in unique_names:\n",
    "    print(f\" - {name}\")\n",
    "\n",
    "base_df = unique_datasets[0].copy()\n",
    "modification_log = []\n",
    "\n",
    "for row in range(base_df.shape[0]):\n",
    "    for col in base_df.columns:\n",
    "        values = [df.at[row, col] for df in unique_datasets]\n",
    "        try:\n",
    "            float_values = [float(v) for v in values]\n",
    "            is_numeric = True\n",
    "        except:\n",
    "            is_numeric = False\n",
    "\n",
    "        if is_numeric:\n",
    "            std_dev = np.std(float_values)\n",
    "            if std_dev < 1e-4:\n",
    "                cleaned_value = round(np.mean(float_values), 4)\n",
    "            else:\n",
    "                rounded = [round(v, 4) for v in float_values]\n",
    "                most_common = Counter(rounded).most_common(1)[0][0]\n",
    "                cleaned_value = most_common\n",
    "        else:\n",
    "            most_common = Counter(values).most_common(1)[0][0]\n",
    "            cleaned_value = most_common\n",
    "\n",
    "        if any(val != cleaned_value for val in values):\n",
    "            modification_log.append({\n",
    "                \"row\": row,\n",
    "                \"column\": col,\n",
    "                \"original_values\": values,\n",
    "                \"cleaned_value\": cleaned_value\n",
    "            })\n",
    "\n",
    "        base_df.at[row, col] = cleaned_value\n",
    "        \n",
    "save_cleaned_output_versioned(base_df, modification_log, num_unique)"
   ],
   "id": "f8e07a104bf99dd2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 unique datasets:\n",
      " - Financial_Records.csv\n",
      " - Financial_Records_Bob.csv\n",
      " - Financial_Records_Bob_Lou_Elah_Susslin.csv\n",
      " - Financial_Records_Bob_Nemanja_Saveski.csv\n",
      " - Financial_Records_Bob_Thomas_Senstyler.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 23\u001B[39m\n\u001B[32m     21\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(base_df.shape[\u001B[32m0\u001B[39m]):\n\u001B[32m     22\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m base_df.columns:\n\u001B[32m---> \u001B[39m\u001B[32m23\u001B[39m         values = [\u001B[43mdf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mat\u001B[49m\u001B[43m[\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcol\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m df \u001B[38;5;129;01min\u001B[39;00m unique_datasets]\n\u001B[32m     24\u001B[39m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     25\u001B[39m             float_values = [\u001B[38;5;28mfloat\u001B[39m(v) \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m values]\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\TU_Wien\\Security_Privacy_and_Explainabiltiy_in_ML\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:2568\u001B[39m, in \u001B[36m_AtIndexer.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   2565\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.ndim == \u001B[32m2\u001B[39m\n\u001B[32m   2566\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.obj.index.is_unique \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.obj.columns.is_unique\n\u001B[32m-> \u001B[39m\u001B[32m2568\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[32m   2569\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.ndim == \u001B[32m2\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m._axes_are_unique:\n\u001B[32m   2570\u001B[39m         \u001B[38;5;66;03m# GH#33041 fall back to .loc\u001B[39;00m\n\u001B[32m   2571\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mall\u001B[39m(is_scalar(x) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m key):\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## V2: Currently best version\n",
    "This version addresses the issue from V1. Also stores data as integers (like in the original), and not float like V1"
   ],
   "id": "d4dbe90da5593ded"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T11:30:32.432735Z",
     "start_time": "2025-04-23T11:28:51.898128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "from dataset_uniqueness_utils import *\n",
    "\n",
    "def is_floatable(x):\n",
    "    try:\n",
    "        float(x)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "DATA_DIR = \"datasets-p2\"\n",
    "OUT_DIR = \"output-datasets\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "unique_datasets, unique_names, num_unique = get_unique_datasets(DATA_DIR)\n",
    "\n",
    "print(f\"Using {num_unique} unique datasets:\")\n",
    "for name in unique_names:\n",
    "    print(f\" - {name}\")\n",
    "\n",
    "base_df = unique_datasets[0].copy()\n",
    "modification_log = []\n",
    "\n",
    "for row in range(base_df.shape[0]):\n",
    "    for col in base_df.columns:\n",
    "        values = [df.at[row, col] for df in unique_datasets]\n",
    "\n",
    "        float_values = []\n",
    "        num_parseable = 0\n",
    "        for v in values:\n",
    "            try:\n",
    "                float_values.append(float(v))\n",
    "                num_parseable += 1\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        if num_parseable == len(values):\n",
    "            std_dev = np.std(float_values)\n",
    "            if std_dev < 1e-4:\n",
    "                cleaned_value = round(np.mean(float_values), 4)\n",
    "            else:\n",
    "                rounded = [round(v, 4) for v in float_values]\n",
    "                most_common = Counter(rounded).most_common(1)[0][0]\n",
    "                cleaned_value = most_common\n",
    "\n",
    "        elif num_parseable == 0:\n",
    "            most_common = Counter(values).most_common(1)[0][0]\n",
    "            cleaned_value = most_common\n",
    "\n",
    "        else:\n",
    "            if random.random() < 0.5:\n",
    "                cleaned_value = round(np.mean(float_values), 4)\n",
    "            else:\n",
    "                cleaned_value = random.choice([v for v in values if not is_floatable(v)])\n",
    "\n",
    "        if any(val != cleaned_value for val in values):\n",
    "            modification_log.append({\n",
    "                \"row\": row,\n",
    "                \"column\": col,\n",
    "                \"original_values\": values,\n",
    "                \"cleaned_value\": cleaned_value\n",
    "            })\n",
    "\n",
    "        try:\n",
    "            base_df.at[row, col] = int(float(cleaned_value))\n",
    "        except:\n",
    "            base_df.at[row, col] = cleaned_value\n",
    "\n",
    "save_cleaned_output_versioned(base_df, modification_log, num_unique)\n"
   ],
   "id": "38316076467459c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 unique datasets:\n",
      " - Financial_Records.csv\n",
      " - Financial_Records_Bob.csv\n",
      " - Financial_Records_Bob_Lou_Elah_Susslin.csv\n",
      " - Financial_Records_Bob_Nemanja_Saveski.csv\n",
      " - Financial_Records_Bob_Thomas_Senstyler.csv\n",
      "Cleaned dataset saved as 'Financial_Records_No_Fingerprint_5_v1.csv' in 'output-datasets\\5_v1'\n",
      "Modification log saved as 'modification_log_5_v1.csv' in 'output-datasets\\5_v1'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output-datasets\\\\5_v1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "97569137cc02afa3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
